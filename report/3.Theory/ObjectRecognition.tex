\section{Object Recognition}
To be able to figure out where the target is, we need to recognize its location within a video stream.
We don't simply need to know the binary question "is there a target?" but rather "where is the target?", so this information can be processed and in turn move the motors to point the laser at the target.
As mentioned in section \ref{sec:obj_tracking}, object recognition algorithms can be tedious to do by hand, and as a result of this, machine learning algorithms will be utilized.
Although the initial target of the device may be a simple and easily recognizable object, the intent is to create a solution that can identify more complicated targets, in a potentially noisy environment.
Because of this, it is important to look into the science of object identification, what algorithms and methods exists, and what libraries we have at our disposal.




\subsection{Neural Networks}

A neural network is, as the name implies, a network of neurons.
It is based on neuroscience, especially the inner workings of the human brain, where a network of neurons is used to make decisions.
The difference being, whether it is a biological neural network or an artificial one, which is the case in a computer science context.
In computer science, a neuron can be seen as a function, taking some input and doing some calculations and then transmitting a processed value to other neurons.

% CITATION NEEDED UNDER MIG V-V
Neural networks is one of the most popular technologies used within machine learning, but also relatively complicated compared to other machine intelligence concepts.
Because of this, simpler solutions should also be considered when possible.
One of the reasons neural networks are especially interesting in this case, is its ability to recognize patterns.
Pattern recognition is a fundamental part of object recognition making neural networks an obvious option.
% føler godt der kan komme lidt mere kød. måske en figure der viser et eksempel? 
% og dog. fordi vi skal jo forvente læseren har basal forståelse for faget. 

\subsubsection{Convolutional Neural Network}
Convolutional neural networks (CNN) are often used for image classification, and is the most popular type of neural network in regards to object detection.
In challenges such as LSVCR\footnote{Imagenet Large Scale Visual Recognition Challenge} the majority of the entries are done using CNN\cite{ILSVRC_Results}.  
A CNN is a neural network in which neurons are grouped into layers.
These layers are grouped in three categories; an input layer, an output layer and a number of so called hidden layers.
The goal of the hidden layers are to transform the input data into the expected output data.
It does this by doing abstractions within each layer, breaking a complex problem into smaller and more trivial sub-problems.

In terms of object recognition, an example could be face recognition.
The first layer could recognize lines, edges or similar low level features.
The following layers could then detect increasingly complicated facial features, ending at some layer, in which one neuron would transmit a signal if a nose is present in the image, and another neuron to transmit if a mouth is present.


\begin{figure}[H]
	\centering
	\includegraphics[scale=0.40]{images/cnn_face.jpg}
	\caption{
		A simplified example of the abstractions within a CNN.
	}
	\label{fig:face_cnn}
\end{figure}
 
However, it is important to understand, that this is not necessarily the patterns that a CNN will detect within its layers.
Actually it is far more likely, that the layers will recognize something that to a human has no relation to a face.
But the computer will have found a correlation between these seemingly random patterns, and a face.

% Mere tekst på næste sætning
Often used along with pooling.

CNNs are an effective choice for classification. 
This means it can answer yes or no to whether the image is of a car.
Now the question is whether it can be used to figure out the position of the objects within the image.
% hvilket nok også skal uddybes og besvares :P  medmindre det er det du gør i de næste sections haha

% Seems to be very good for still images, but not so much for video tracking https://en.wikipedia.org/wiki/Convolutional_neural_network#Video_analysis


\subsubsection{Regional Convolutional Neural Network}


\subsection{GOTURN}
% https://www.learnopencv.com/goturn-deep-learning-based-object-tracking/
Generic Object Tracking Using Regression Networks, is an algorithm based on deep learning.\cite{goturn}
GOTURN is different than the majority of algorithms presented in this section, in that it uses offline learning, whereas online learning constantly improves the model during runtime.
It is fed a large library of videos of different objects and is taught with the help of this.
The model is then shipped with the algorithm implementation.
The benefit of this, is that it runs more quickly, as it doesn't have to ever modify the model or analyse whether the given result is relevant.
However, this comes at a cost. 
The algorithm has a tendency to favor objects within the training set, even if they remain stationary.
So, for instance, if we want to track a bird flying past stationary planes, it might lock onto the planes rather than the bird, even though the planes are not moving.
This is due to the unpredictable-ness of what the algorithm see as a correlation between video and a correct answer.


The GOTURN algorithm utilizes CNN, which is explained in the previous sub-section.
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.80]{images/GOTURN-architecture.jpg}
	\caption{
		How the algorithm utilizes CNN, source \cite{goturn}
	}
	\label{fig:goturn-arch}
\end{figure}
GOTURN works by looking at two frames the first, also known as previous frame, and the second, also known as current frame.
This is also shown on Figure \ref{fig:goturn-arch}.
The premise is that the location of the object is known in previous frame, and a bounding box is present.
Based on the bounding box of the previous frame, the current frame is cropped to two times the size of the previous bounding box.
A CNN is then trained to predict the bounding box in the second frame.


Some possible problems with this algorithm is that the location of the target isn't known initially, as the target will not necessarily be in the picture at startup time, and will eventually leave the image feed again, as our device will have idle time.
Another possible issue would be depending on th speed of the given target and the frame-rate of the camera, as the object might have left the cropped area. 
This could be solved by a larger crop, however this makes it less relevant.

\subsection{You Only Look Once}
You Only Look Once (YOLO) ...



\subsection{OpenCV}
One option is to simply utilize the highly popular OpenCV library.
OpenCV is an open source computer vision library, that comes with ready to use object tracking functionality.
% Write more



\subsection{Tensorflow}
Tensorflow is a framework for working with machine learning.
It is made for python, and is quite beginner friendly but still with the possibilities of delving deeper into the inner workings of a given model, and the processes of it.

% Mine noter af ting at skrive
	% what is a tensor
	% training
	% exporting from it
	% can be used with any alogrithm 
	% hvorfor er det så nice at arbejde med
	% hvordan kan vi få brug af dette


% Things to check / consider writing about
% https://en.wikipedia.org/wiki/Computer_vision#Recognition
% https://en.wikipedia.org/wiki/Video_tracking
% Kernel-based tracking
% Contour tracking
% https://en.wikipedia.org/wiki/Kalman_filter
% Particle filter
% https://en.wikipedia.org/wiki/Outline_of_object_recognition
% real-time: triangulate each frame and measure the persistence of selected triangles relative to their location in each successive frame. Microprocessors such as the raspberry pi are fast enough so that triangulation and triangle measurement can be done in a few milliseconds.
% ^^ Few miliseconds (Sounds like maybe around 5ms, would alow for updating robot position 20 times a second (capture 20 fps from the camera too). Which could be a goal to aim at (RTS: scheduling bla bla, update canon position 20 times pr second...))
% Would be cool in RTS part to integrate some functionality to handle if camera data is not ready within the 5 ms, or if the device is not ready to handle input after 5 ms. The MI part could be coded to update each 5 ms.