\section{Object Tracking}
\label{sec:obj_tracking}

To be able to track or know where the target is located, the device will require sensors that can transmit information about the position of the desired target.
One could imagine a couple of different sensors that could potentially gather information about the position of the target.
For instance, laser and sonar could both be used to gather some information about the position of a target\cite{Sensors}.
However, since the system should be adaptable to a dynamic environment with potentially a lot of different objects in motion, one sensor was deemed the most obvious choice for this system; a camera.

Using a camera is powerful, since images can be processed in order to determine what objects are present in the image.
Once the location of the object is determined within the image, the direction of the target can be calculated.
Assuming that the camera is aimed in the same direction as the laser, the direction in which to aim will simply be calculated based on the delta $X$ and $Y$ coordinates of the target within the image.

Unfortunately, the camera does also come with a couple of disadvantages.
First of all, a normal camera will not be able to determine the distance to a target.
Secondly, the camera will give a lot of excessive information, which will have to be processed in order to only keep the relevant information. 
As a matter of fact, the relevant information is not even directly provided but rather deduced based on the information.
As for the distance, the camera could be used along with a laser sensor used for the distance measuring\cite{Sensors}.

\subsection{Image processing}
Not only does the camera output too much information, but furthermore, the camera does not even directly provide the actual information needed.
The image will have to be processed in order to figure out where the target is located within.
Unfortunately it is no easy task to recognize objects in images, and writing an algorithm that solves this problem can be quite tedious.
However, there are a couple of different methods that can be used when detecting objects.

Object recognition is a classic computer vision problem, and a lot of research exists in this field.
Generally speaking there are two approaches to this problem.

\subsubsection{Hand-coded features}
As previously mentioned, it may be very tedious to write an object recognition algorithm by hand.
However, if the object has some distinct features, it may also be fairly straight forward to implement by hand.
Imagine that an algorithm were to detect a red ball. 
Given the two features \textit{round} and \text{red}, it would probably be a manageable task to implement an algorithm that would detect a red ball.

Although the hand-coded algorithms may be usable given a few distinct features, it will quickly fall short when given the task to detect a face or a bird.

\subsubsection{Machine learning}\label{sec:obj_tracking:sub:ML}
Rather than trying to describe a complex object using an algorithm, an often-used alternative is to let the computer figure out the features of the object itself.
This is what is referred to as machine learning.

Machine learning is a common term used when a computer teaches itself to solve a given task\cite{ArtificialIntelligencealanpoole}.
There are a wide variety of tasks that are very complicated to solve using algorithms, but easier to solve simply by letting the computer learn how to solve them. 
Some common examples are, for instance, object localization, object detection, object classification, speech recognition or learning the best tactics of games like chess.

Apart from the implementation of object localization, one could also imagine that machine learning could be applied in our system to predict the trajectory of the object that is being tracked.
So machine learning will be highly relevant and something to consider when developing the system.
