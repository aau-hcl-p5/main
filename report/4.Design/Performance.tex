\section{Performance}
In order to be able to track an object in real time, the object localization will have to happen in real time.
Therefore, the algorithms should be tested in order to determine whether they will be able to execute the object localization fast enough for it to be feasible for the project.

\subsection{Raspberry Pi}
The Raspberry Pi 3B is the desired host of the MI processing, but it is very limited in the amount of resources available to it.
It comes with a 1.2GHz Quadcore ARM Cortex-A53, 64Bit processor and 1 GB of RAM.
The Raspberry Pi is described in more detail in subsection~\ref{platformtakeaways}.
In relation to computation power, the Raspberry Pi is a little underwhelming compared to an average consumer computer.
Therefore, although an algorithm might execute quickly enough on a normal computer, it is essential for it to be tested whether it will also be quick enough when executed on the Raspberry Pi.

\subsection{Object fill algorithm}
The object fill algorithm is limited by the frame rate of the camera on an average to high end laptop, meaning that it could serve as a good baseline for further object localization algorithms.

The results of the conducted tests show that the Raspberry Pi took approximately 0.07 seconds to analyze a frame.
This is roughly equivalent to an acceptable but not amazing frame rate of 15 frames per second.
In addition, the algorithm slowed down significantly in the worst case scenario, where no object is to be found within the frame.
In this case, the algorithm was only able to process just below 10 frames per second.
Although this may seem troublesome, it is not much of a concern since the robot does not need to update once no object is within the frame, and the performance will increase as soon as the object is found.

\subsection{Thresh Moment algorithm}
Thresh Moment turned out to be quite a bit faster than the Object Fill algorithm.
This may initially come as a surprise, since the two algorithms are quite identical, and if anything, the Thresh Moment algorithm will do more iterations over the image.

The improved performance is due to the fact that the utilized OpenCV functions are from a library written in a low level language.
This means, that while the Object Fill algorithm does all the heavy lifting within python, the Thresh Moment algorithm will take advantage of the much faster languages C and C++, that OpenCV is written in.

It turns out, that the Raspberry Pi has no trouble running the Thresh Moment algorithm, and outputs results faster than the webcam updates.

\subsection{YOLO}
As YOLO is praised as one of the fastest object detection algorithms some tests were conducted in order to determine if it would be a viable option for the project\cite{yolospeed}.

The conducted benchmark tests used the fastest version of YOLO, called YOLO2 light along with a pretrained lightweight model with a size of 33.8 MB on a modern high-end laptop, the Dell XPS 15.
YOLO2 is essentially an iteration of YOLO, focused mainly on improving performance, without sacrificing accuracy\cite{yolospeed}.
The Dell XPS used in the test has a Quad-Core Intel I7 7700HQ with a base 2.8 GHz clock speed along with 16 GB of RAM.

The tests conducted using YOLO2 light rendered impressive results regarding accuracy.
Unfortunately the performance was no good as the XPS only managed to analyze around 2 frames per second on average.

There should be a couple of notes regarding these results.
First of all, the tests were conducted with YOLO utilizing the CPU.
Normally YOLO would utilize the GPU in order to achieve far better performance results, but as the Raspberry Pi will not be able to utilize a powerful GPU, testing on the GPU was deemed unnecessary.
Another thing to note is the still fairly large model of 33.8 MB.
In the simple case of localizing a single object, this model could surely be decreased a lot in complexity, which in turn would render better performance results.

Furthermore, as previously mentioned, YOLO is an object detection algorithm.
This means the algorithm will try to locate and classify all objects in the image.
Performance could presumably be improved by only having a single class to classify and then terminate the algorithm as soon as the first object was localized.
However, it was decided that making modifications to YOLO would likely be too tedious, while risking that the modifications would still not make it fast enough to run on the Raspberry Pi.

\subsection{Other machine learning algorithms}
Since no machine learning algorithms claim to be drastically faster than YOLO, it should be safe to assume that no current machine learning object localization algorithm will be quick enough to run on a Raspberry Pi.

%\subsection{Scikit classifier}
%\todo{Fill this if we are able to create a proper classifier with scikit}

\subsection{Conclusion}
In conclusion, it was determined that the YOLO algorithm would not be feasible for this project.
This also means that the machine learning application that will be further explored is the variable motor power.