\section{Calibration}\label{sec:calibration}
As explained in \autoref{des:sec:variablemotorpower} varying power was required depending on the current revolution of each motor, and the direction of movement.

To solve this problem, data was gathered for the minimum amount of power required to change the revolution.
This data was then processed in a neural network, finding a relation between power and revolution in each direction.
The neural network was then exported to C code and compiled on the NXT, and used as a base-value for motor power.

To collect the data regarding the required power, a function was created on the NXT.
This function slowly increases power while checking for a change in the current revolution. 
A simplified version of the function can be seen in \autoref{lst:GetRequiredPower}.


\begin{lstlisting}[language=C,label={lst:GetRequiredPower},caption={Getting required power to move }]
int8_t get_power_to_move(T_AXIS_TYPE axis, T_DIRECTION direction) {
	int8_t power = MIN_POWER;
	T_REVOLUTION first_revolution = get_current_revolution();
	
	do {
		set_motor_speed(axis, power * (direction == POSITIVE ? 1 : -1));
		power++;
		
		// wait 30ms but make sure we don't move in that timeframe
		for(int i = 0; i < 30; i++)
		{
			systick_wait_ms(1);
			if (!should_stop_moving(first_revolution, power))
				break;
		}
	
	} while(should_stop_moving(first_revolution, power));
	
	set_motor_speed(axis, 0);
	
	return power;
}

\end{lstlisting}

The \texttt{should\_stop\_moving} function will determine whether the motor has moved, or if the power exceeds the maximum allowed power, meaning it is unable to move further.
The data is sent back to a host machine over the established USB connection.

The function was run multiple times, and whenever the device was modified, the calibration function was run again.

One of these data-sets, where the calibration process was run 5 times, can be seen in \autoref{fig:calibdata}.
This data-set is based on the y-axis, in an upwards direction.


\figur{1}{images/calib_data.png}{Required power for revolution on motor}{fig:calibdata}

There is a clear tendency in the data, even though it has some noise, which is presumably due to motor insecurities.
The tendency seems reasonable regarding the upwards motion, where it initially requires low effort, but the requirement increases as it is reaching horizontal level.

Using this data, a neural network was trained to find the tendency of the data.
The training was done with the Python module, scikit-learn\cite{scikit-learn}, which exposes a regressor called \texttt{MPLRegressor}, which was utilized as shown in \autoref{lst:mlpregressor}.
A custom modified version of the module was created, to be able to use a custom activation function.
This was done because of issues with the nxtOSEK system, regarding the usage of the \texttt{math.h} library in C, which was not usable for among others the \texttt{exp} function.
Because of this an approximation of the sigmoid function was implemented.

\autoref{lst:mlpregressor} shows how to train a multi layered neural network for regression.

\begin{lstlisting}[language=python,label={lst:mlpregressor},caption={Training a MLPRegressor with scikit}]
model = MLPRegressor(
hidden_layer_sizes=(30,),
activation='approx_sigmoid',
max_iter=100000,
tol=0.0000001,
verbose=True
)
model.fit(inp, expect)

\end{lstlisting}

The \texttt{MLPRegressor} has a lot of parameters that can be modified in order to tweak the neural network for the required use case.
A custom amount of hidden layers was required as the default argument value was 100 neurons in one layer, which was not necessary for the rather simple data.
30 neurons in one layer was decided upon after testing different sizes.
A larger hidden layer did not improve the quality, however smaller networks seemed to decrease precision.

The system also utilized the custom implementation of the sigmoid function, and increased max iterations, and lowered the tolerance to make the network run for a longer time before stopping.
This makes sure the network is presumably good enough to be used in the system.

One of the networks created with 30 neurons is shown in \autoref{fig:calibdatann}, where the line is the result of the neural network.
The data is normalized to better work with the SGD function, using a preprocessor exposed by the scikit-learn module.
Optimally a \textit{Gaussian distribution}, with zero mean and unit variance, would have been used, but due to the problems with \texttt{math.h}, this was not feasible.

\figur{1}{images/calib_data_nn.png}{Sample fitting of the data}{fig:calibdatann}

\autoref{fig:calibdatann} shows the neural network for the upwards direction, however the same process was done simultaneously for the downwards direction.
Calibration was only done for the $Y$-axis.
The two separate neural networks, produced at another calibration test, can be seen in \autoref{fig:calibdatannboth}.


\figur{1}{images/calib_data_nn_both.png}{Both neural networks of the $Y$ axis}{fig:calibdatannboth}

These neural networks had to be used to calculate the base value of a motion at a given revolution at a given time.
To solve this, the weight and biases of the neural networks had to be exported to the NXT device.
This was done by generating the C code needed to replicate the behavior.
A simplistic version of such a file can be seen in \autoref{lst:exportedmodel}.


\begin{lstlisting}[language=C,label={lst:exportedmodel},firstnumber={1},caption={Autogenerated model for getting power to move up}]
#include <stdint.h>
#include <math.h>

typedef struct {
	double input_0;
} T_MODEL_INPUT;

typedef struct {
	double output_0;
} T_MODEL_EXECUTION_RESULT;

static double sigmoid(double value)
{
	double x = value >= 0 ? value : value * -1;
	double x2 = x * x;
	double e = 1.0f + x + x2 * 0.555f + x2 * x2 * 0.143f;
	return 1.0f / (1.0f + (value > 0 ? 1.0f / e : e));
}
static double WEIGHTS_LAYER_0[1][30] = {
	{ 0.6808517232629588, ...., 4.170499471133788 }
};
static double WEIGHTS_LAYER_1[30][1] = {
	{ 0.8428497309705472 },
	...
	{ -2.015815865114775 }
};
static double BIAS_LAYER_0[30] = {
	-0.8555370213729661, ...., 3.3193827456697775
};
static double BIAS_LAYER_1[1] = {
	0.09092457039425662
};
T_MODEL_EXECUTION_RESULT calculate_model_up(T_MODEL_INPUT input) {
	//calculate result
}

\end{lstlisting}
The function \texttt{calculate\_model\_up} first normalizes the input data, and then calculates the output as explained in \ref{sec:calculationsNN}.
At last the output value is denormalized in order to be used in the system.
This function is used in the movement module, to calculate the base power.
This is explained in detail in \autoref{sec:movement}.


