\section{Development practices}
\subsection{Introduction}
When developing a project, especilly when the primary goal of the project is learning, it is important to also consider the process.
With this in mind, the following section will elaborate on how the group has been working together.
The section will be divided into subsections regarding each type of problem, and how it has been handled by the group.

\subsection{SCRUM}
Our cooperation practices were heavily inspired by SCRUM and were intended to allow for an agile project, as a lot of the issues in a research-based project, will arise during the project.
However, using SCRUM rigorously was not feasible, as the project had a very concrete deadline, and the lack of an actual customer.
With this in mind, the principles from SCRUM that suited our project were used, instead of blindly following one specific ideology.


The process was based around sprints, a week in length, starting and ending on a Tuesday, as that week day made most sense in relation to lectures.

\subsection{Milestones}
Initially, after we realized what area we wanted to work with, we defined a set of milestones that covered the whole project, from start to project hand in.
The milestone plan was based around a rough estimate of the time it would take to write different sections of the report and the different code modules.

The initial plan was as follows, with sprint index, start date, and the overall goal of the sprint:
\begin{enumerate}
	\item sprint01: 2018-09-11 - setup
	\item sprint02: 2018-09-18 - Start on analysis and theory
	\item sprint03: 2018-09-25 - Analysis done 
	\item sprint04: 2018-10-02 - Architecture done
	\item sprint05: 2018-10-09 - Theory done
	\item sprint06: 2018-10-16 - Start on development + Start on documentation
	\item sprint07: 2018-10-23 - RASP -> NXT communication done.
	\item sprint08: 2018-10-30 - Movement-module works
	\item sprint09: 2018-11-06 - Basic Image recognition
	\item sprint10: 2018-11-13
	\item sprint11: 2018-11-20 - Motion Prediction module done
	\item sprint12: 2018-11-27 - Product done
	\item sprint13: 2018-12-04 - Documentation Done
	\item sprint14: 2018-12-11 - Conclusion and meta section done
	\item sprint15: 2018-12-18 - proofreading done [SPRINT IS ONLY 2 DAYS]
\end{enumerate}

The milestone plan followed our sprints, and gave each sprint a title, which indicated the intended focus of the sprint.

This allowed us to roughly keep track of our progress, however our early estimates were a bit too generous, as the machine learning and the scheduler took significantly longer than anticipated, both due to unforseen obstacles, but also due to iteration on the solution.

\todo{Link to part where we talk about fuckups in NXT and in ML}
Due to these complications, the timelime was adjusted as the project went along.

At the end of a project, a more detailed plan, made daily was used instead, mainly to keep track of the missing parts of the project.

\todo{should we have a revised plan? yes, just in appendix}

\subsection{Sprints}
All sprints started with a meeting.
The meeting was typically held on tuesdays, as it allowed for work to be done before the weekend, with monday being reserved for review and merging of the different issues, before the next meeting on tuesday.
This meeting had three mandatory topics.
\begin{itemize}
	\item Standup
	\item Review
	\item Planning
\end{itemize}

During \textbf{standup} each member reported on the issues they had the last sprint.
This included mentioning any issues in solving the problem, as well as sharing any interesting implementation details.
In real SCRUM you would utilize daily standup meetings, but this did not make sense, work on the project was not done daily.
We learned that SCRUM makes more sense when working a full work week.

A problem stemming from this was the lack of clarity in regards to progress on every members card, and whether it would be closed.

This problem was reduced, later, as we learned to update each other and ask each other for updates through our chat service.
In the last two sprints we introduced daily standups as everyone met in the group room on daily.


After the standup a \textbf{review} followed.
The review evaluted on the previous sprint as a whole, such as progress and whether the card estimations were correct, and the current and future direction of the project.
This created an iterative process of improvement, which helped with a large variety of issues.
We had a pleasant and open atmosphere, where it was okay to critique others work in a constructive way.

%The meetings had a tendency to last a few hours, which was good as things were discussed at length, however we had a tendency to drift off course, which made it more difficult to pay attention when we came back on course.
%This problem was reduced through the review process.

\textbf{Planning}, where the weekly team-lead would present the issues that he had prepared for the sprint. 
The team-lead, was chosen each week, and would make sure people would close their given issues, and he would prepare a list of issues for the coming sprint.
Preparing the issues meant making sure their description was acceptable, with a Definition of Done and adding any relevant notes to the description.
At the meeting the team lead explained a given card, and the whole team estimated the amount of points required to solve the given card by using planning poker.
If estimations differed wildly, a discussion in regards to the actual intended work of the card would be had. 
%hader would be had, sorry, ved bare ikke hvad ellers.

After the issues in the sprint planned by the project lead, each member would say how many points they expected to burn in the coming sprint.
If the amount of points in the pre-planned sprint was larger than the estimated amount to be burnable, issues would be moved out, and if it was smaller, more issues would be estimated.
Finally, each member would assign themselves to issues they wished to work on, and any leftovers would be assigned by the team-lead.

The value of a point was estimated at the first sprint meeting.
Later on, most issues ended up having scores of 5 or 8, which was often quite inaccurate.
As thus, the value of a point was recalibrated, allowing for a greater range of points, with larger issues more commonly taking 13 or 20 points, instead of 8, and smaller points taking 1, 2 or 5.
This allowed for more precise estimation of issues.
%dunno about this.
%Ved godt det nok egentligt burde hedde cards, men vi har arbejdet ud fra at det hed issues, s√•.

\section{Communication}
When communicating in a development team, face to face communication is preferred, which was the reasoning for a weekly standup meeting.

As every member of the group had a job, in addition to school, individual work was preferred in the beginning.

However as difficulties arose, especially in regards to NXT development, a weekly workday was introduced on Thursdays.
Thursday was chosen as it fit best with the schedule, and because it allowed the group members to get an idea of any problems in their issues, that might be good to work on together.

This could be through discussion, instant feedback on different work items, or using different techniques, such as pair programming, or rubber ducking of of a person.

Pair programming became a powerful tool when working with NXTOsek, as proper documentation was lacking, and therefore development was difficult.
Working together helped with development in these cases and provided valuable discussion and improved the speed of development considerably.
These different techniques, were not mandatory.
Rather, they were tools for use in specific cases, as pair programming does not make sense when writing simple code.
The principles of pair programming were also utilized when proof reading critical parts of the report, as a dynamic discussion of phrasing and topics, provided a larger variety of options.

To communicate during the week, Slack was used.
Slack is a free to use chat platform, with both direct messaging, as well as channels.

Channels were created for different topics, with \texttt{\#general} mainly being used for communication that was essential to the group as a whole, such as meeting times, planning work together or any issues with tools.
Channels like \texttt{\#report} and \texttt{\#development}, were meant for discussion relating to the report or the development.

Good use of Slack, eliminated a lot of problems that were introduced by the wish to not meet daily.

 
In addition to our communication, bots for the tools in use were also added.
These bots were triggered by events in Jira, Github and TeamCity, which were used for issue tracking, version control and continuous development, respectively, and centralized all notifications regarding the project in one platform.

The tools will be covered in the following sections.

\section{issue tracking}
Jira,\todo{citation needed} is a propriety issue-tracking system, with a large variety of features and integrations.
We bought a licence in a previous semester, and self hosted the system on a personal server.


Having an online issue-reporting system made it easy for the team members, regardless of location, to add, update and read issues. 
When a new task or bug arose, an issue was created.

Jira was also used for hosting the Kanban board.

During the last two sprints, a physical Kanban board was used instead, as it allowed for easier tracking of progress.
%During the last two sprints we introduced a physical Kanban board, which created a competitive environment, created by the thrill of physically moving an issue from 'doing' to 'review', or seeing someone else finished issues faster than you.
%plz no

The service also has automatically generated burn-down charts, but these did not make much sense when development didn't happen on a daily basis, so an expected line would not be possible.
Burn-down charts for the last two sprints were created by hand each morning, as a part of the daily standup, as crunch-period motivation.


\section{Quality Gates}
and we tried catching as many bugs and typos, before they would become integrated parts of the software and report. 
High quality is always important, and to ensure quality, version control with strict quality gates and an extensive review process was used.

For version control the Git protocol, through GitHub, was used.
To keep track of different versions of the project, 3 main branch types was used, a master branch, a develop branch and feature branches.

Feature branches were used for development of issues.
This meant that each issue had a corresponding feature branch.

The develop branch could also be called the sprint branch.
All feature branches are merged into the develop branch during the week.
These merges could only happen with a pull request that has 1) an accepted review by one or more members, 2) has succesfully passed all of our tests.

The develop branch was merged into the master branch weekly or biweekly, often after the weekly standup meeting.
This merge also included another indepth readthrough of the changes from the just finished sprint, and often included several members.
Thus, grammar and content reviews were spread throughout the duration of the project, instead of happening only at the end.

As mentioned, whenever a pull-request was created a set of tests are run.
These tests differ in nature, from readability tests to functionality tests.

Examples of readability tests include checking the LaTex code for multiple sentences on a single line.
This test was added to ease commenting in GitHub during the merge review process, as well as reduce the possiblity of merge conflicts, as it is easier to merge on a sentence level, rather than an arbitrary line level.

Another example of cosmetic tests were code linting, which simply checked the Python and C code for any non-standard code.
This includes, but is not limited to, indentation, spacing, tabularity.
For Python, PyLint was used \todo{Citation needed}, while the C linting was implemented by the project group.

In addition to the cosmetic tests, functionality tests were also added.
The functionality tests primarily consisted of unit tests, but also included a few integration tests where applicable.
The python code was tested with \todo{whatever we used} a generic python test framework, while the C code framework was written by ourselves.
An initial goal for the project, was to ensure a 75\% test coverage across the codebase.
While the python codebase did fulfill this requirement at 81\% the C part did not.

Finally the robot was tested extensively by hand, and the individual modules of the solution were also tested such as hardware tests, described in Section~\ref{des:sec:hwtest} and performance tests of the different image localization algorithms, described in Section~\ref{des:sec:performance}.
