\section{Future work}\label{sec:futurework}
Throughout the development of a project, there are often several ideas that are deprioritized for one reason or another.
This section will describe the ideas that the group had, our initial thoughts, how they might have been implemented and why they were not implemented.


\textbf{Predict target location in x frames}\\
A \textbf{Should have} requirement from the MosCow analysis in Section~\ref{subsec:requirements}, was the ability to predict the location x frames into the future.
In the actual implementation this was not done, as a different solution proved better.
However to hit a projectile, this would be a requirement.
The initial idea was to train the model by simply moving the object in front of a camera and tracking how the object moved.
A potential additional requirement here would be classification, as distinction between objects would be necessary, as different objects move differently, unless of course, it was assumed that only a single type of object would be seen, for example the balloon used for testing.


\textbf{Firing a projectile}\\
During our MosCow analysis, the ability to hit a moving target with a projectile was assigned as a \textbf{Could have}.
The ability to do this, would require making predictions for the movement of the object, to be able to fire the projectile at a location.
This would require knowing the speed of the projectile when launched, the trajectory of the object


\textbf{Machine Learning for detecting if a human is the targeted object}\\
As the device currently only looks for the color red, it could potentially hit a person wearing a red shirt, or even just a person with redder than average skin.
This is obviously a problem, as a laser is actually quite dangerous and can potentially cause damage to the human eye.
Even if the ability to fire a projectile was added, hitting a human with a projectile would be a problem.

A way to solve this, would be to add a classifier to object localization.
The classifier would classify the detected object, and if it was a human that was found, it would send a \textit{Non-valid target found}, to tell the machine that a target was found or a \textit{target not found} status code.
Potentially it could even be integrated with the next bit of future work:


\textbf{Machine Learning instead of color detection}\\
Currently the device uses OpenCV color detection, as described in Section~\ref{solution:objfillalgo}.
There were a multitude of reasons for this, the primary one being that the hardware available, a Raspberry Pi, was simply not fast enough, as described in Section~\ref{des:sec:performance}.
However, as the goal of the project was to prevent bird collisions at airports, the ability to distinguish between a plane and a bird would be an essential requirement, when implementing the device for real world use.
This could be solved with two simple things:
\begin{enumerate}
    \item Acquire more powerful hardware.
    \item Train the model used in \ref{des:sec:performance}.
\end{enumerate}
As working with images on computers is typically best done on the GPU as it is actually designed for the purpose, a requirement for the real world device would be a powerful GPU.
YOLO recommends a GPU in the range of an Nvidia Titan, but a less powerful GPU could definitely do the job.
